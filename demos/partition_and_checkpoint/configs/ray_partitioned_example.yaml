# Example configuration for Partitioned Ray Executor
# This configuration enables fault-tolerant partitioning for large datasets

# Basic configuration
project_name: 'partitioned-ray-example'
dataset_path: 'data/large-dataset.jsonl'
export_path: 'outputs/partitioned-ray-result.jsonl'

# Ray configuration
executor_type: 'ray_partitioned'  # Use the new partitioned executor
ray_address: 'auto'  # Auto-detect Ray cluster

# Partitioning configuration
partition_size: 10000  # Number of samples per partition
max_partition_size_mb: 128  # Maximum partition size in MB
enable_fault_tolerance: true  # Enable fault tolerance features
max_retries: 3  # Maximum retry attempts per partition
preserve_intermediate_data: false  # Save intermediate data after each operation
cleanup_temp_files: true  # Clean up temporary partition files after completion

# Data format configuration for performance optimization
storage_format: 'parquet'  # parquet, arrow, jsonl - Use parquet for maximum compression, arrow for memory mapping
use_arrow_batches: true  # Use Arrow batch format for processing (recommended)
arrow_batch_size: 1000  # Arrow batch size for processing
arrow_memory_mapping: false  # Enable memory mapping for Arrow files (use for large files)

# Processing configuration
np: 4  # Number of processes (will be overridden by Ray cluster resources)
use_cache: false  # Disable cache for partitioned processing
op_fusion: true  # Enable operator fusion
fusion_strategy: 'probe'  # Use probe-based fusion strategy

# Processing pipeline
process:
  - whitespace_normalization_mapper:
  - token_num_filter:
      hf_tokenizer: 'EleutherAI/pythia-6.9b-deduped'
      min_num: 10
      max_num: 1000
  - document_deduplicator:
      lowercase: true
      ignore_non_character: true
  - language_id_score_filter:
      lang: 'en'
      min_score: 0.8
  - text_length_filter:
      min_len: 50
      max_len: 2000
  - topk_specified_field_selector:
      field_key: '__dj__stats__.num_token'
      topk: 10000

# Work directory for checkpoints and temporary files
work_dir: './work_dir' 