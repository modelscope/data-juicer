# ç»¼åˆåˆ†åŒºå’Œæ£€æŸ¥ç‚¹æŒ‡å—

æœ¬æŒ‡å—æ¶µç›– Data-Juicer åˆ†åŒºå’Œæ£€æŸ¥ç‚¹ç³»ç»Ÿçš„å®é™…ä½¿ç”¨ï¼Œæä¾›æ„å»ºå®¹é”™ã€å¯æ‰©å±•å’Œå¯è§‚æµ‹æ•°æ®å¤„ç†ç®¡é“çš„åŠ¨æ‰‹ç¤ºä¾‹ã€æ•…éšœæ’é™¤å’Œæœ€ä½³å®è·µã€‚

> **ğŸ“š æœ‰å…³è¯¦ç»†æ¶æ„ä¿¡æ¯å’Œå¯è§†åŒ–å›¾è¡¨ï¼Œè¯·å‚é˜…:**
> - [Partitioning_Checkpointing_EventLogging_Architecture.md](Partitioning_Checkpointing_EventLogging_Architecture.md) - å¸¦æœ‰å¯è§†åŒ–å›¾è¡¨çš„å®Œæ•´æ¶æ„æ–‡æ¡£
> - [Partitioning_Checkpointing_EventLogging_Summary.md](Partitioning_Checkpointing_EventLogging_Summary.md) - æ‰§è¡Œæ¦‚è¿°å’Œå¿«é€Ÿå‚è€ƒ

## ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
3. [é…ç½®æŒ‡å—](#é…ç½®æŒ‡å—)
4. [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
5. [ç›‘æ§å’Œè°ƒè¯•](#ç›‘æ§å’Œè°ƒè¯•)
6. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
7. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
8. [å·¥ä½œç›®å½•ç»“æ„](#å·¥ä½œç›®å½•ç»“æ„)

## æ¦‚è¿°

Data-Juicer åˆ†åŒºå’Œæ£€æŸ¥ç‚¹ç³»ç»Ÿä¸ºå¤„ç†å¤§å‹æ•°æ®é›†æä¾›ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆï¼š

- **ğŸ”§ å®¹é”™æ€§**: ä½¿ç”¨æ£€æŸ¥ç‚¹è‡ªåŠ¨ä»æ•…éšœä¸­æ¢å¤
- **ğŸ“ˆ å¯æ‰©å±•æ€§**: åŸºäºåˆ†åŒºçš„å¤„ç†ï¼Œé€‚ç”¨äºä»»ä½•è§„æ¨¡çš„æ•°æ®é›†
- **ğŸ‘ï¸ å¯è§‚æµ‹æ€§**: å…¨é¢çš„äº‹ä»¶æ—¥å¿—è®°å½•å’Œå®æ—¶ç›‘æ§
- **âš¡ æ€§èƒ½**: ä¼˜åŒ–çš„å­˜å‚¨æ ¼å¼å’Œå¹¶è¡Œå¤„ç†
- **ğŸ”„ çµæ´»æ€§**: å¯é…ç½®çš„åˆ†åŒºå’Œæ£€æŸ¥ç‚¹ç­–ç•¥

### å…³é”®ç»„ä»¶

- **åˆ†åŒºå¼•æ“**: å°†å¤§å‹æ•°æ®é›†åˆ†å‰²ä¸ºå¯ç®¡ç†çš„å—
- **æ£€æŸ¥ç‚¹ç®¡ç†å™¨**: ä¿å­˜å’Œæ¢å¤å¤„ç†çŠ¶æ€
- **äº‹ä»¶è®°å½•å™¨**: è·Ÿè¸ªæ‰€æœ‰æ“ä½œå’Œæ€§èƒ½æŒ‡æ ‡
- **Ray é›†ç¾¤**: æä¾›åˆ†å¸ƒå¼å¤„ç†èƒ½åŠ›
- **ç»“æœåˆå¹¶å™¨**: å°†å¤„ç†åçš„åˆ†åŒºåˆå¹¶ä¸ºæœ€ç»ˆè¾“å‡º

## å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬é…ç½®

```yaml
# åŸºæœ¬è®¾ç½®
project_name: 'my-partitioned-project'
dataset_path: 'data/large-dataset.jsonl'
export_path: 'outputs/processed-dataset.jsonl'
executor_type: 'ray_partitioned'

# Ray é…ç½®
ray_address: 'auto'

# åˆ†åŒºé…ç½®
partition_size: 10000
max_partition_size_mb: 128
enable_fault_tolerance: true
max_retries: 3

# å­˜å‚¨é…ç½®
storage_format: 'parquet'
preserve_intermediate_data: true

# äº‹ä»¶æ—¥å¿—
event_logging:
  enabled: true
  log_level: 'INFO'
  max_log_size_mb: 100
  backup_count: 5

# å¤„ç†ç®¡é“
process:
  - whitespace_normalization_mapper:
  - text_length_filter:
      min_len: 50
      max_len: 2000
  - language_id_score_filter:
      lang: 'en'
      min_score: 0.8
```

### 2. åŸºæœ¬ä½¿ç”¨

```python
from data_juicer.config import init_configs
from data_juicer.core.executor.ray_executor_partitioned import PartitionedRayExecutor

# åŠ è½½é…ç½®
cfg = init_configs()

# åˆ›å»ºæ‰§è¡Œå™¨
executor = PartitionedRayExecutor(cfg)

# è¿è¡Œå¤„ç†
result = executor.run()

# è·å–äº‹ä»¶å’Œæ€§èƒ½æ•°æ®
events = executor.get_events()
perf_summary = executor.get_performance_summary()
print(f"è®°å½•äº† {len(events)} ä¸ªäº‹ä»¶")
print(f"æ€§èƒ½: {perf_summary}")
```

## é…ç½®æŒ‡å—

### åˆ†åŒºé…ç½®

```yaml
# åˆ†åŒºè®¾ç½®
partition_size: 10000              # æ¯ä¸ªåˆ†åŒºçš„æ ·æœ¬æ•°
max_partition_size_mb: 128         # æœ€å¤§åˆ†åŒºæ–‡ä»¶å¤§å°
enable_fault_tolerance: true       # å¯ç”¨å®¹é”™
max_retries: 3                     # æœ€å¤§é‡è¯•æ¬¡æ•°
```

**åˆ†åŒºç­–ç•¥:**
- **åŸºäºæ ·æœ¬**: æ§åˆ¶æ¯ä¸ªåˆ†åŒºçš„æ ·æœ¬æ•°
- **åŸºäºå¤§å°**: æ§åˆ¶åˆ†åŒºæ–‡ä»¶å¤§å°
- **è‡ªé€‚åº”**: åŸºäºæ•°æ®é›†ç‰¹å¾çš„è‡ªåŠ¨å¤§å°è®¡ç®—

### æ£€æŸ¥ç‚¹é…ç½®

```yaml
# æ£€æŸ¥ç‚¹è®¾ç½®
preserve_intermediate_data: true
storage_format: 'parquet'          # parquet, arrow, jsonl

checkpointing:
  enabled: true
  storage_format: 'parquet'
  compression: 'snappy'
  max_checkpoints_per_partition: 10
  cleanup_old_checkpoints: true
```

**å­˜å‚¨æ ¼å¼æ¯”è¾ƒ:**
- **Parquet**: æœ€ä½³å‹ç¼©ï¼ˆ3-5å€ï¼‰ã€å¿«é€ŸI/Oã€ç”Ÿäº§å°±ç»ª
- **Arrow**: å†…å­˜é«˜æ•ˆã€é›¶æ‹·è´è¯»å–ã€å†…å­˜å¤„ç†
- **JSONL**: äººç±»å¯è¯»ã€é€šç”¨å…¼å®¹æ€§ã€è°ƒè¯•

### äº‹ä»¶æ—¥å¿—é…ç½®

```yaml
# äº‹ä»¶æ—¥å¿—è®¾ç½®
event_logging:
  enabled: true
  log_level: 'INFO'                # DEBUG, INFO, WARNING, ERROR
  max_log_size_mb: 100
  backup_count: 5
  log_to_console: true
  log_to_file: true
```

### æ€§èƒ½é…ç½®

```yaml
# æ€§èƒ½è°ƒä¼˜
performance:
  batch_size: 1000
  prefetch_factor: 2
  num_workers: 4
  memory_limit_gb: 8
  enable_compression: true
  use_arrow_batches: true
  arrow_batch_size: 1000
```

## ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºæœ¬å¤„ç†

```python
from data_juicer.config import init_configs
from data_juicer.core.executor.ray_executor_partitioned import PartitionedRayExecutor

# åŠ è½½é…ç½®
cfg = init_configs('config.yaml')

# åˆ›å»ºæ‰§è¡Œå™¨
executor = PartitionedRayExecutor(cfg)

# è¿è¡Œå¤„ç†
result_dataset = executor.run()

# è®¿é—®ç»“æœ
print(f"å¤„ç†äº† {len(result_dataset)} ä¸ªæ ·æœ¬")
```

### 2. å®æ—¶ç›‘æ§

```python
# å®æ—¶ç›‘æ§äº‹ä»¶
for event in executor.monitor_events():
    print(f"[{event.timestamp:.3f}] {event.event_type.value}: {event.message}")
    
    if event.event_type == EventType.OPERATION_ERROR:
        print(f"é”™è¯¯: {event.error_message}")
```

### 3. äº‹ä»¶åˆ†æ

```python
# è·å–æ‰€æœ‰äº‹ä»¶
events = executor.get_events()

# æŒ‰ç±»å‹è¿‡æ»¤
partition_events = executor.get_events(event_type=EventType.PARTITION_COMPLETE)
print(f"å®Œæˆçš„åˆ†åŒº: {len(partition_events)}")

# è·å–ç‰¹å®šæ“ä½œçš„æ€§èƒ½
filter_perf = executor.get_performance_summary(operation_name="text_length_filter")
print(f"è¿‡æ»¤å™¨æ€§èƒ½: {filter_perf}")

# ç”Ÿæˆç»¼åˆæŠ¥å‘Š
report = executor.generate_status_report()
print(report)
```

### 4. å‘½ä»¤è¡Œä½¿ç”¨

```bash
# åŸºæœ¬æ¼”ç¤º
python demos/partition_and_checkpoint/comprehensive_partitioning_demo.py

# ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†
python demos/partition_and_checkpoint/comprehensive_partitioning_demo.py --dataset data/my_dataset.jsonl

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python demos/partition_and_checkpoint/comprehensive_partitioning_demo.py --config my_config.yaml

# å¸¦åˆ†æ
python demos/partition_and_checkpoint/comprehensive_partitioning_demo.py --analyze
```

## ç›‘æ§å’Œè°ƒè¯•

### 1. å®æ—¶çŠ¶æ€ç›‘æ§

```python
# è·å–å½“å‰çŠ¶æ€
status = executor.get_status_summary()
print(f"æˆåŠŸç‡: {status['success_rate']:.1%}")
print(f"æ´»åŠ¨åˆ†åŒº: {status['active_partitions']}")
print(f"å®Œæˆçš„åˆ†åŒº: {status['completed_partitions']}")

# ç›‘æ§ç‰¹å®šåˆ†åŒº
partition_status = executor.get_partition_status(partition_id=0)
print(f"åˆ†åŒºçŠ¶æ€: {partition_status['status']}")
```

### 2. äº‹ä»¶åˆ†æ

```python
# è·å–æ‰€æœ‰äº‹ä»¶
events = executor.get_events()

# æŒ‰äº‹ä»¶ç±»å‹è¿‡æ»¤
partition_events = executor.get_events(event_type=EventType.PARTITION_COMPLETE)
operation_events = executor.get_events(event_type=EventType.OPERATION_START)

# æŒ‰åˆ†åŒºè¿‡æ»¤
partition_events = executor.get_events(partition_id=0)

# æŒ‰æ—¶é—´èŒƒå›´è¿‡æ»¤
recent_events = executor.get_events(start_time=time.time() - 3600)
```

### 3. æ£€æŸ¥ç‚¹åˆ†æ

```python
# è·å–åˆ†åŒºçš„æœ€æ–°æ£€æŸ¥ç‚¹
checkpoint = executor.checkpoint_manager.get_latest_checkpoint(partition_id=0)

# åŠ è½½æ£€æŸ¥ç‚¹æ•°æ®
data = executor.checkpoint_manager.load_checkpoint(checkpoint)

# åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹
checkpoints = executor.checkpoint_manager.list_checkpoints(partition_id=0)
```

### 4. æ€§èƒ½åˆ†æ

```python
# è·å–æ€§èƒ½æ‘˜è¦
perf_summary = executor.get_performance_summary()
print(f"æ€»å¤„ç†æ—¶é—´: {perf_summary['total_time']:.2f}s")
print(f"å¹³å‡åˆ†åŒºæ—¶é—´: {perf_summary['avg_partition_time']:.2f}s")

# è·å–æ“ä½œç‰¹å®šæ€§èƒ½
op_perf = executor.get_performance_summary(operation_name="text_length_filter")
print(f"è¿‡æ»¤å™¨æ“ä½œ: {op_perf}")
```

## æœ€ä½³å®è·µ

### 1. åˆ†åŒºç­–ç•¥

- **ä»å°å¼€å§‹**: ä»è¾ƒå°çš„åˆ†åŒºï¼ˆ1,000-10,000 æ ·æœ¬ï¼‰å¼€å§‹ï¼Œæ ¹æ®æ€§èƒ½è°ƒæ•´
- **è€ƒè™‘å†…å­˜**: ç¡®ä¿åˆ†åŒºé€‚åˆå¯ç”¨å†…å­˜ï¼ˆé€šå¸¸ 128MB-1GBï¼‰
- **å¹³è¡¡è´Ÿè½½**: ç›®æ ‡åˆ†åŒºå¤§å°ç›¸ä¼¼ä»¥è·å¾—æ›´å¥½çš„è´Ÿè½½å‡è¡¡
- **ç›‘æ§æ€§èƒ½**: è·Ÿè¸ªåˆ†åŒºå¤„ç†æ—¶é—´å¹¶ç›¸åº”è°ƒæ•´

### 2. æ£€æŸ¥ç‚¹ç­–ç•¥

- **ä¸ºé•¿ç®¡é“å¯ç”¨**: å¯¹å…·æœ‰å¤šä¸ªæ“ä½œçš„ç®¡é“ä½¿ç”¨æ£€æŸ¥ç‚¹
- **é€‰æ‹©å­˜å‚¨æ ¼å¼**: ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ Parquetï¼ˆå‹ç¼© + æ€§èƒ½ï¼‰
- **å®šæœŸæ¸…ç†**: å¯ç”¨è‡ªåŠ¨æ£€æŸ¥ç‚¹æ¸…ç†ä»¥èŠ‚çœç£ç›˜ç©ºé—´
- **ç›‘æ§ç£ç›˜ä½¿ç”¨**: è·Ÿè¸ªæ£€æŸ¥ç‚¹å­˜å‚¨ä½¿ç”¨

### 3. å®¹é”™

- **è®¾ç½®åˆç†é‡è¯•**: 2-3 æ¬¡é‡è¯•é€šå¸¸è¶³å¤Ÿ
- **ç›‘æ§æ•…éšœ**: è·Ÿè¸ªæ•…éšœæ¨¡å¼ä»¥è¯†åˆ«ç³»ç»Ÿæ€§é—®é¢˜
- **ä½¿ç”¨æ£€æŸ¥ç‚¹**: å¯ç”¨æ£€æŸ¥ç‚¹æ¢å¤ä»¥è·å¾—æ›´å¥½çš„å®¹é”™
- **å¤„ç†éƒ¨åˆ†æ•…éšœ**: è®¾è®¡ç®¡é“ä»¥ä¼˜é›…åœ°å¤„ç†éƒ¨åˆ†æ•…éšœ

### 4. æ€§èƒ½ä¼˜åŒ–

- **ä½¿ç”¨ Parquet**: å‹ç¼©å’Œæ€§èƒ½çš„æœ€ä½³å¹³è¡¡
- **å¯ç”¨å‹ç¼©**: å¯¹æ£€æŸ¥ç‚¹ä½¿ç”¨ Snappy å‹ç¼©
- **ä¼˜åŒ–æ‰¹å¤§å°**: æ ¹æ®å†…å­˜å’Œæ€§èƒ½è°ƒæ•´æ‰¹å¤§å°
- **ç›‘æ§èµ„æº**: è·Ÿè¸ª CPUã€å†…å­˜å’Œç£ç›˜ä½¿ç”¨

### 5. ç›‘æ§å’Œè°ƒè¯•

- **å¯ç”¨äº‹ä»¶æ—¥å¿—**: ç”Ÿäº§ç¯å¢ƒå§‹ç»ˆå¯ç”¨äº‹ä»¶æ—¥å¿—
- **è®¾ç½®å‘Šè­¦**: ç›‘æ§é«˜æ•…éšœç‡æˆ–æ€§èƒ½é—®é¢˜
- **å®šæœŸåˆ†æ**: å®šæœŸåˆ†æäº‹ä»¶æ—¥å¿—ä»¥æŸ¥æ‰¾æ¨¡å¼
- **ä¿ç•™æ—¥å¿—**: ä¿ç•™æ—¥å¿—ç”¨äºè°ƒè¯•å’Œåˆè§„

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å†…å­˜é—®é¢˜

**ç—‡çŠ¶**: OutOfMemoryErrorã€å¤„ç†ç¼“æ…¢ã€é«˜å†…å­˜ä½¿ç”¨
**è§£å†³æ–¹æ¡ˆ**:
- å‡å°‘åˆ†åŒºå¤§å°ï¼ˆ`partition_size`ï¼‰
- å¯ç”¨æ£€æŸ¥ç‚¹æ¸…ç†ï¼ˆ`cleanup_old_checkpoints: true`ï¼‰
- ä½¿ç”¨ Parquet æ ¼å¼ä»¥è·å¾—æ›´å¥½çš„å‹ç¼©
- å¢åŠ å¯ç”¨å†…å­˜æˆ–å‡å°‘ `memory_limit_gb`

#### 2. ç£ç›˜ç©ºé—´é—®é¢˜

**ç—‡çŠ¶**: DiskFullErrorã€æ£€æŸ¥ç‚¹æ•…éšœã€å­˜å‚¨è­¦å‘Š
**è§£å†³æ–¹æ¡ˆ**:
- å¯ç”¨æ£€æŸ¥ç‚¹æ¸…ç†ï¼ˆ`cleanup_old_checkpoints: true`ï¼‰
- ä½¿ç”¨å‹ç¼©ï¼ˆ`compression: 'snappy'`ï¼‰
- ç›‘æ§å·¥ä½œç›®å½•ä¸­çš„ç£ç›˜ä½¿ç”¨
- æ¸…ç†æ—§çš„å·¥ä½œç›®å½•

#### 3. é«˜æ•…éšœç‡

**ç—‡çŠ¶**: è®¸å¤šå¤±è´¥çš„åˆ†åŒºã€ä½æˆåŠŸç‡ã€é‡è¯•å¾ªç¯
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥æ“ä½œé…ç½®å’Œæ•°æ®è´¨é‡
- æŸ¥çœ‹äº‹ä»¶æ–‡ä»¶ä¸­çš„é”™è¯¯æ—¥å¿—
- å¢åŠ é‡è¯•æ¬¡æ•°ï¼ˆ`max_retries`ï¼‰
- éªŒè¯æ•°æ®é›†æ ¼å¼å’Œæ¨¡å¼

#### 4. å¤„ç†ç¼“æ…¢

**ç—‡çŠ¶**: é•¿å¤„ç†æ—¶é—´ã€ä½ååé‡ã€èµ„æºç“¶é¢ˆ
**è§£å†³æ–¹æ¡ˆ**:
- åŸºäºå¯ç”¨å†…å­˜ä¼˜åŒ–åˆ†åŒºå¤§å°
- ä½¿ç”¨æ›´å¤šå·¥ä½œå™¨ï¼ˆ`num_workers`ï¼‰
- å¯ç”¨æ“ä½œèåˆ
- ä½¿ç”¨é«˜æ•ˆçš„å­˜å‚¨æ ¼å¼ï¼ˆParquet/Arrowï¼‰

#### 5. äº‹ä»¶æ—¥å¿—é—®é¢˜

**ç—‡çŠ¶**: ç¼ºå°‘äº‹ä»¶ã€æ—¥å¿—æŸåã€é«˜æ—¥å¿—æ–‡ä»¶å¤§å°
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥æ—¥å¿—è½®è½¬è®¾ç½®ï¼ˆ`max_log_size_mb`ã€`backup_count`ï¼‰
- éªŒè¯æ—¥å¿—æ–‡ä»¶çš„ç£ç›˜ç©ºé—´
- æ£€æŸ¥æ—¥å¿—çº§åˆ«é…ç½®
- ç›‘æ§æ—¥å¿—æ–‡ä»¶å¢é•¿

### è°ƒè¯•æ­¥éª¤

1. **æ£€æŸ¥äº‹ä»¶æ—¥å¿—**: æŸ¥çœ‹å¤„ç†äº‹ä»¶ä¸­çš„é”™è¯¯
   ```python
   error_events = executor.get_events(event_type=EventType.OPERATION_ERROR)
   for event in error_events:
       print(f"{event.operation_name} ä¸­çš„é”™è¯¯: {event.error_message}")
   ```

2. **åˆ†æå¤±è´¥çš„åˆ†åŒº**: æ£€æŸ¥å¤±è´¥åˆ†åŒºçš„è¯¦ç»†ä¿¡æ¯
   ```python
   failed_partitions = executor.get_events(event_type=EventType.PARTITION_ERROR)
   for event in failed_partitions:
       print(f"åˆ†åŒº {event.partition_id} å¤±è´¥: {event.error_message}")
   ```

3. **éªŒè¯æ£€æŸ¥ç‚¹**: æ£€æŸ¥æ£€æŸ¥ç‚¹å¯ç”¨æ€§å’Œå®Œæ•´æ€§
   ```python
   checkpoints = executor.checkpoint_manager.list_checkpoints(partition_id=0)
   print(f"å¯ç”¨æ£€æŸ¥ç‚¹: {len(checkpoints)}")
   ```

4. **ç›‘æ§èµ„æº**: è·Ÿè¸ª CPUã€å†…å­˜å’Œç£ç›˜ä½¿ç”¨
   ```python
   perf_summary = executor.get_performance_summary()
   print(f"èµ„æºä½¿ç”¨: {perf_summary['resource_usage']}")
   ```

5. **æ£€æŸ¥é…ç½®**: éªŒè¯é…ç½®è®¾ç½®
   ```python
   print(f"å½“å‰é…ç½®: {executor.config}")
   ```

### è·å–å¸®åŠ©

- æ£€æŸ¥å·¥ä½œç›®å½•ä»¥è·å–è¯¦ç»†çš„æ—¥å¿—å’ŒæŠ¥å‘Š
- æŸ¥çœ‹äº‹ä»¶æ—¥å¿—ä»¥è·å–ç‰¹å®šé”™è¯¯æ¶ˆæ¯
- åˆ†ææ£€æŸ¥ç‚¹æ•°æ®ä»¥æŸ¥æ‰¾æ•°æ®è´¨é‡é—®é¢˜
- ç›‘æ§ç³»ç»Ÿèµ„æºä»¥æŸ¥æ‰¾æ€§èƒ½ç“¶é¢ˆ
- ä½¿ç”¨ç»¼åˆçŠ¶æ€æŠ¥å‘Šè·å–ç³»ç»Ÿæ¦‚è¿°

## å·¥ä½œç›®å½•ç»“æ„

å·¥ä½œç›®å½•åŒ…å«æ‰€æœ‰å¤„ç†å·¥ä»¶ï¼Œç»„ç»‡å¦‚ä¸‹ï¼š

```
work_dir/
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ dataset_mapping.json      # åˆ†åŒºæ˜ å°„ä¿¡æ¯
â”‚   â””â”€â”€ final_mapping_report.json # æœ€ç»ˆå¤„ç†æŠ¥å‘Š
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ processing_events.jsonl   # äº‹ä»¶æ—¥å¿—ï¼ˆJSONL æ ¼å¼ï¼‰
â”‚   â”œâ”€â”€ processing_summary.json   # å¤„ç†æ‘˜è¦
â”‚   â””â”€â”€ performance_metrics.json  # æ€§èƒ½æŒ‡æ ‡
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ partition_000000/
â”‚       â”œâ”€â”€ op_000_whitespace_normalization_mapper.parquet
â”‚       â”œâ”€â”€ op_001_text_length_filter.parquet
â”‚       â””â”€â”€ metadata.json         # æ£€æŸ¥ç‚¹å…ƒæ•°æ®
â”œâ”€â”€ partitions/
â”‚   â”œâ”€â”€ partition_000000.parquet  # åŸå§‹åˆ†åŒº
â”‚   â””â”€â”€ partition_000001.parquet
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ partition_000000_processed.parquet  # å¤„ç†åçš„åˆ†åŒº
â”‚   â””â”€â”€ partition_000001_processed.parquet
â””â”€â”€ temp/                         # ä¸´æ—¶æ–‡ä»¶
    â”œâ”€â”€ ray_objects/
    â””â”€â”€ intermediate_data/
```

### å…³é”®æ–‡ä»¶

- **`metadata/dataset_mapping.json`**: å®Œæ•´çš„åˆ†åŒºæ˜ å°„å’Œå…ƒæ•°æ®
- **`logs/processing_events.jsonl`**: JSONL æ ¼å¼çš„æ‰€æœ‰å¤„ç†äº‹ä»¶
- **`logs/processing_summary.json`**: æœ€ç»ˆå¤„ç†æ‘˜è¦å’Œç»Ÿè®¡
- **`checkpoints/`**: ç”¨äºæ•…éšœæ¢å¤çš„æ“ä½œçº§æ£€æŸ¥ç‚¹
- **`partitions/`**: åŸå§‹æ•°æ®é›†åˆ†åŒº
- **`results/`**: æœ€ç»ˆå¤„ç†åçš„åˆ†åŒº

### æ—¥å¿—æ–‡ä»¶åˆ†æ

```python
# åˆ†æäº‹ä»¶æ—¥å¿—
import json

with open('work_dir/logs/processing_events.jsonl', 'r') as f:
    for line in f:
        event = json.loads(line)
        if event['event_type'] == 'OPERATION_ERROR':
            print(f"é”™è¯¯: {event['error_message']}")

# åŠ è½½å¤„ç†æ‘˜è¦
with open('work_dir/logs/processing_summary.json', 'r') as f:
    summary = json.load(f)
    print(f"æˆåŠŸç‡: {summary['success_rate']:.1%}")
```

## ç»“è®º

Data-Juicer åˆ†åŒºå’Œæ£€æŸ¥ç‚¹ç³»ç»Ÿä¸ºå¤„ç†å¤§å‹æ•°æ®é›†æä¾›äº†å¼ºå¤§ã€å¯æ‰©å±•å’Œå¯è§‚æµ‹çš„è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡éµå¾ªæœ¬æŒ‡å—ä¸­æ¦‚è¿°çš„æœ€ä½³å®è·µï¼Œæ‚¨å¯ä»¥æ„å»ºå¯é çš„æ•°æ®å¤„ç†ç®¡é“ï¼Œä¼˜é›…åœ°å¤„ç†æ•…éšœå¹¶æä¾›å¤„ç†æ€§èƒ½çš„è¯¦ç»†è§è§£ã€‚

æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒï¼š
- [Partitioning_Checkpointing_EventLogging_Architecture.md](Partitioning_Checkpointing_EventLogging_Architecture.md) - å®Œæ•´æ¶æ„æ–‡æ¡£
- [Partitioning_Checkpointing_EventLogging_Summary.md](Partitioning_Checkpointing_EventLogging_Summary.md) - æ‰§è¡Œæ¦‚è¿°
- [Ray_Partitioning_Optimization.md](Ray_Partitioning_Optimization.md) - Ray ç‰¹å®šä¼˜åŒ–
- [Universal_Event_Logging_Guide.md](Universal_Event_Logging_Guide.md) - äº‹ä»¶æ—¥å¿—ç³»ç»Ÿ 