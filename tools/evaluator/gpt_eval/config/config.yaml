answer_generation:
  model_name: my_model
  question_file: ./config/question.jsonl
  answer_file: ./answer/myorg/mymodel.jsonl
  batch_size: 4
  max_tokens: 512
  temperature: 0.7
  # config for huggingface
  huggingface:
    model_path: myorg/mymodel
    tokenizer_path: myorg/mymodel
  # # config for openai
  # openai:
  #   openai_organization:
  #   openai_api_key:
  #   model:
  #   max_retry:
  # # config for megatron-lm
  # megatron:
  #   process_num:
  #   checkpoint_path:
  #   tokenizer_type:
  #   vocab_path:
  #   merge_path:
  #   iteration:
gpt_evaluation:
  # openai config
  openai_organization:
  openai_api_key:
  # files config
  question_file: ./config/question.jsonl
  answer_file:    ./answer/myorg/mymodel.jsonl
  baseline_file: ./answer/openai/gpt-3.5-turbo.jsonl
  prompt_file: ./config/prompt.jsonl
  reviewer_file: ./config/reviewer.jsonl
  result_file: ./review/myorg/mymodel-gpt3.5-turbo.jsonl
