# This is the main config file of auto prompting optimization for a grader model.
# This is a typical iterative sandbox pipeline.

# global parameters
project_name: 'sandbox-auto-prompt-optimization'
experiment_name: 'grader-prompt'                                          # for wandb tracer name
work_dir: './outputs/auto-prompt-optimization-for-grader-model'           # the default output dir for meta logging
resume: true                                                              # allow resume from the existing context infos

# iteration related parameters
max_iter_num: 5
iter_targets:
  - "grader_model_prompt_optimization.grades_evaluation.min_mse <= 0.2"
iter_updater:
  select_and_merge_data_pools.merge_single_prompt_data_pools.merged_top_prompt_dataset: grader_model_prompt_optimization.generate_new_prompts.dj_configs.dataset_path

pipelines:
  - grader_model_prompt_optimization:
      execution_job_configs:
        - hook: 'ProcessDataHook'
          meta_name: 'generate_new_prompts'
          output: 'generated_prompts_path'
          dj_configs: 'configs/data_juicer_recipes/sandbox/auto_prompt_optimization/dj_configs_prompt_generating.yaml'
        - hook: 'DataPoolManipulationHook'
          meta_name: 'construct_single_prompt_data_pools'
          input:
            extra_configs.dataset_path: '-1.generated_prompts_path'
          output: 'single_prompt_data_pool_paths'
          extra_configs:
            type: 'data_pool_construction'
            dataset_path: '<updated_by_the_input_mapping>'
            export_path: './outputs/auto-prompt-optimization-for-grader-model/single_prompt_data_pools/'
            split_num: 1
            ignore_stats: true
        - hook: 'DataPoolManipulationHook'
          meta_name: 'join_prompts_and_datasets_to_infer'
          input:
            extra_configs.dataset_path_1: '-1.single_prompt_data_pool_paths'
          output: 'datasets_to_infer_with_updated_prompts'
          extra_configs:
            type: 'data_pool_cartesian_join'
            dataset_path_1: '<replaced_by_the_input>'
            dataset_path_2:
              - 'demos/data/auto-prompt-optim/init_infer_dataset.jsonl'
            export_path: './outputs/auto-prompt-optimization-for-grader-model/datasets_to_infer/'
        - hook: 'InferModelHook'
          meta_name: 'grader_model_inference'
          input:
            extra_configs.dataset_path: '-1.datasets_to_infer_with_updated_prompts'
          output: 'grader_model_inference_result'
          extra_configs:
            # model related
            type: 'api'
            model: 'qwen2.5-32b-instruct'
            max_retry_num: 5
            build_messages_func: 'build_messages_for_math_qa'
            parse_output_func: 'parse_output'
            func_kwargs:
              system_key: "prompt"
              query_key: "question"
              response_key: "answer"
            # data related
            dataset_path: '<replaced_by_the_input>'
            export_path: './outputs/auto-prompt-optimization-for-grader-model/infer_results/'
            infer_res_key: 'grades'
      evaluation_job_configs:
        - hook: 'EvaluateDataHook'
          meta_name: 'grades_evaluation'
          input:
            extra_configs.predicted_dataset_path: '-1.grader_model_inference_result'
          output:
            - 'single_prompt_eval_results'
            - 'min_mse'
          extra_configs:
            type: 'mse'
            predicted_dataset_path: '<replaced_by_the_input>'
            predicted_value_key: 'grades'
            ground_truth_value_key: 'truth'
  - select_and_merge_data_pools:
      probe_job_configs:
        - hook: 'GeneralProbeHook'
          meta_name: 'rank_single_prompt_data_pools'
          input:
            extra_configs.dataset_path: 'grader_model_prompt_optimization.construct_single_prompt_data_pools.single_prompt_data_pool_paths'
            extra_configs.metrics: '-1.single_prompt_eval_results'
          output: 'top3_prompt_data_pool_paths'
          extra_configs:
            type: 'data_pool_ranking'
            dataset_path: '<updated_by_the_input_mapping>'
            metrics: '<updated_by_the_input_mapping>'
            ranking_keys:
              - 'mse'
              - 'format_error'
            descending: false
            top_n: 3
      execution_job_configs:
        - hook: 'DataPoolManipulationHook'
          meta_name: 'merge_single_prompt_data_pools'
          input:
            extra_configs.dataset_path: '-1.top3_prompt_data_pool_paths'
          output: 'merged_top_prompt_dataset'
          extra_configs:
            type: 'data_pool_merging'
            dataset_path: '<updated_by_the_input_mapping>'
            export_path: './outputs/auto-prompt-optimization-for-grader-model/merged_top_generated_prompts/new_prompts.jsonl'
