# This is the main config file for reproducing the Sandbox experiments for InternVL COCO Caption task.
#
# You can follow the doc [here](https://internvl.readthedocs.io/en/latest/get_started/installation.html) to install
# the InternVL before starting it, or you can only need to clone and let the sandbox create and install the environment
# automatically.
# Then you need to prepare the model and dataset following this doc [here](https://internvl.readthedocs.io/en/latest/tutorials/coco_caption_finetune.html#).

# global parameters
project_name: 'sandbox-internvl-coco-caption'
experiment_name: 'sandbox-internvl'              # for wandb tracer name
work_dir: './outputs/sandbox-internvl'                # the default output dir for meta logging

# configs for each job, the jobs will be executed according to the order in the list
probe_job_configs:
  # Baseline Preparation:
  # 1. convert the coco caption
  # 2. downsample the whole dataset randomly to form a baseline data pool with only 1/3 size of the original one
  # 3. analyze the data for all image & text stats
  # 4. prepare data pools according to the analyzed data, and add the baseline data pool
  # 5. prepare the meta files for these single-op data pools in step 4
  # 6. start the training for single-op data pools
  # 7. start the evaluation for models trained on single-op data pools
  # 8. rank data pools according to the evaluation results, the rank method is specified to the relative improvements
  #   to the model trained on baseline data pool
  # 9. combine the top data pools to several combined data pools
  # 10. downsampling the data pools to align with the one with the least samples, including the baseline data pool
  # 11. prepare meta files for the combined and downsampled data pools in step 10
  # 12. start the training for multiple-op data pools
  # 13. start the evaluation for models trained on multiple-op data pools
  # 14. rank data pools according to the evaluation results, the rank method is specified to the relative improvements
  #   to the model trained on the aligned baseline data pool
  # 15. start the training for top-3 multiple-op data pools on larger scales (2B, 4B, 26B)
  # 16. start the evaluation for models trained on top-3 multiple-op data pools on larger scales

  - hook: 'ProbeViaAnalyzerHook'
    meta_name: 'analysis_ori_data'
    dj_configs: 'configs/demo/process.yaml'
    extra_configs:
  # - hook: 'ProbeViaModelInferHook'
  #   meta_name: 'analysis_ori_model'
  #   dj_configs:
  #     dataset_path: './demos/data/demo-dataset.jsonl'
  #     export_path: './outputs/demo-sandbox/demo-sandbox.jsonl'
  #     data_probe_algo: 'uniform'
  #     data_probe_ratio: 0.5
  #     extra_configs:
  #       (...model configs)

refine_recipe_job_configs:
  - hook: 'RefineRecipeViaKSigmaHook'
    meta_name: 'analysis_ori_data'
    dj_configs: 'configs/demo/process.yaml'
    extra_configs:
      path_k_sigma_recipe: './outputs/demo-process/k_sigma_new_recipe.yaml'
  # - hook: 'RefineRecipeViaModelFeedbackHook'
  #   meta_name:
  #   dj_configs:
  #   extra_configs:
  #     (...model configs)

execution_job_configs:
  - hook: 'ProcessDataHook'
    meta_name:
    dj_configs: './outputs/demo-process/k_sigma_new_recipe.yaml'
    extra_configs:
  - hook: 'TrainModelHook'
    meta_name:
    dj_configs:
    extra_configs: 'configs/demo/sandbox/gpt3_extra_train_config.json'

evaluation_job_configs:
  - hook: 'ProbeViaAnalyzerHook'
    meta_name: 'analysis_processed_data'
    dj_configs: 'configs/demo/process.yaml'
    extra_configs:
  # - hook: 'ProbeViaModelInferHook'
  #   meta_name: 'analysis_trained_model'
  #   dj_configs:
  #     dataset_path: './demos/data/demo-dataset.jsonl'
  #     export_path: './outputs/demo-sandbox/demo-sandbox.jsonl'
  #     data_probe_algo: 'uniform'
  #     data_probe_ratio: 0.5
  #     extra_configs:
  #       (...model configs)
  - hook: 'EvaluateDataHook'
    meta_name: 'eval_data'
    dj_configs:
    extra_configs: 'configs/demo/sandbox/gpt3_data_quality_eval_config.yaml'
  # - hook: 'EvaluateModelHook'
  #   meta_name: 'eval_model'
  #   dj_configs:
  #   oextra_configs:
  #     (...model configs)
