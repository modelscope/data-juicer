type: easyanimate
model_name: "easyanimate"
trainer_name: "easyanimate-lora-trainer"
train:
  tracker_config:
    # config for wandb
    project_name: "demo-bench"
    experiment_name: 'demo-single-op-model-train'
  model_path:
    # path to the pixart model or the hugging face model
    pretrained_model_name_or_path: "PixArt-alpha/PixArt-XL-2-512x512"
    # path to pretrained easyanimate checkpoint. Following are the links to available checkpoints.
    # https://dail-wlcb.oss-cn-wulanchabu.aliyuncs.com/dj-competition/modelscope_sora/models/easyanimate_mm_16x256x256_pretrain.safetensors
    transformer_path: "/PATH/TO/EASYANIMATE_MODEL"
  dataset_path:
    # The root directory to videos. Set empty if it is the absolute path in the dataset.
    dataset_name: ""
    # path to the Data-Juicer dataset. Note that the root path is in "thirdparth/models/EasyAnimate"
    dataset_meta_name: "../../../outputs/demo-bench/demo-dataset-for-train.jsonl"
  training_config:
    # image size, must match the pretrained easyanimate checkpoint.
    sample_size: 256
    mixed_precision: "bf16"
    batch_size_per_gpu: 8
    gradient_accumulation_steps: 1
    num_train_epochs: 1
    dataloader_num_workers: 8
    seed: 42
  saving_config:
    # Note that the root path is in "thirdparth/models/EasyAnimate"
    output_dir: "../../../outputs/demo-bench/models"
