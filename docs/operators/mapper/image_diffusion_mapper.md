# image_diffusion_mapper

Generate images using a diffusion model based on provided captions.

This operator uses a Hugging Face diffusion model to generate images from given captions. It supports different modes for retaining generated samples, including random selection, similarity-based selection, and retaining all. The operator can also generate captions if none are provided, using a Hugging Face image-to-sequence model. The strength parameter controls the extent of transformation from the reference image, and the guidance scale influences how closely the generated images match the text prompt. Generated images can be saved in a specified directory or the same directory as the input files. This is a batched operation, processing multiple samples at once and producing a specified number of augmented images per sample.

ä½¿ç”¨åŸºäºæä¾›çš„å­—å¹•çš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒã€‚

æ­¤è¿ç®—ç¬¦ä½¿ç”¨æ‹¥æŠ±é¢éƒ¨æ‰©æ•£æ¨¡å‹ä»ç»™å®šçš„å­—å¹•ç”Ÿæˆå›¾åƒã€‚å®ƒæ”¯æŒä¸åŒçš„æ¨¡å¼æ¥ä¿ç•™ç”Ÿæˆçš„æ ·æœ¬ï¼ŒåŒ…æ‹¬éšæœºé€‰æ‹©ã€åŸºäºç›¸ä¼¼æ€§çš„é€‰æ‹©å’Œå…¨éƒ¨ä¿ç•™ã€‚å¦‚æœæ²¡æœ‰æä¾›å­—å¹•ï¼Œåˆ™æ“ä½œå‘˜è¿˜å¯ä»¥ä½¿ç”¨æ‹¥æŠ±é¢éƒ¨å›¾åƒåˆ°åºåˆ—æ¨¡å‹æ¥ç”Ÿæˆå­—å¹•ã€‚â€œå¼ºåº¦â€ å‚æ•°æ§åˆ¶ä»å‚è€ƒå›¾åƒå˜æ¢çš„ç¨‹åº¦ï¼Œâ€œæŒ‡å¯¼æ¯”ä¾‹â€ å½±å“ç”Ÿæˆçš„å›¾åƒä¸æ–‡æœ¬æç¤ºçš„åŒ¹é…ç¨‹åº¦ã€‚ç”Ÿæˆçš„å›¾åƒå¯ä»¥ä¿å­˜åœ¨æŒ‡å®šçš„ç›®å½•ä¸­ï¼Œä¹Ÿå¯ä»¥ä¿å­˜åœ¨ä¸è¾“å…¥æ–‡ä»¶ç›¸åŒçš„ç›®å½•ä¸­ã€‚è¿™æ˜¯ä¸€ä¸ªæ‰¹å¤„ç†æ“ä½œï¼Œä¸€æ¬¡å¤„ç†å¤šä¸ªæ ·æœ¬ï¼Œå¹¶ä¸ºæ¯ä¸ªæ ·æœ¬ç”ŸæˆæŒ‡å®šæ•°é‡çš„å¢å¼ºå›¾åƒã€‚

Type ç®—å­ç±»å‹: **mapper**

Tags æ ‡ç­¾: cpu, hf, multimodal

## ğŸ”§ Parameter Configuration å‚æ•°é…ç½®
| name å‚æ•°å | type ç±»å‹ | default é»˜è®¤å€¼ | desc è¯´æ˜ |
|--------|------|--------|------|
| `hf_diffusion` | <class 'str'> | `'CompVis/stable-diffusion-v1-4'` | diffusion model name on huggingface to generate |
| `trust_remote_code` | <class 'bool'> | `False` |  |
| `torch_dtype` | <class 'str'> | `'fp32'` | the floating point type used to load the diffusion |
| `revision` | <class 'str'> | `'main'` | The specific model version to use. It can be a |
| `strength` | typing.Annotated[float, FieldInfo(annotation=NoneType, required=True, metadata=[Ge(ge=0), Le(le=1)])] | `0.8` | Indicates extent to transform the reference image. |
| `guidance_scale` | <class 'float'> | `7.5` | A higher guidance scale value encourages the |
| `aug_num` | typing.Annotated[int, Gt(gt=0)] | `1` | The image number to be produced by stable-diffusion |
| `keep_original_sample` | <class 'bool'> | `True` | whether to keep the original sample. If |
| `caption_key` | typing.Optional[str] | `None` | the key name of fields in samples to store captions |
| `hf_img2seq` | <class 'str'> | `'Salesforce/blip2-opt-2.7b'` | model name on huggingface to generate caption if |
| `save_dir` | <class 'str'> | `None` | The directory where generated image files will be stored. |
| `args` |  | `''` |  |
| `kwargs` |  | `''` |  |

## ğŸ“Š Effect demonstration æ•ˆæœæ¼”ç¤º
not available æš‚æ— 

## ğŸ”— related links ç›¸å…³é“¾æ¥
- [source code æºä»£ç ](../../../data_juicer/ops/mapper/image_diffusion_mapper.py)
- [unit test å•å…ƒæµ‹è¯•](../../../tests/ops/mapper/test_image_diffusion_mapper.py)
- [Return operator list è¿”å›ç®—å­åˆ—è¡¨](../../Operators.md)