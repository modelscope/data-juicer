# image_captioning_mapper

Generates image captions using a Hugging Face model and appends them to samples.

This operator generates captions for images in the input samples using a specified Hugging Face model. It can generate multiple captions per image and apply different strategies to retain the generated captions. The operator supports three retention modes: 'random_any', 'similar_one_simhash', and 'all'. In 'random_any' mode, a random caption is retained. In 'similar_one_simhash' mode, the most similar caption to the original text (based on SimHash) is retained. In 'all' mode, all generated captions are concatenated and retained. The operator can also keep or discard the original sample based on the `keep_original_sample` parameter. If both `prompt` and `prompt_key` are set, the `prompt_key` takes precedence.

ä½¿ç”¨ Hugging Face æ¨¡å‹ç”Ÿæˆå›¾åƒæè¿°å¹¶å°†å…¶é™„åŠ åˆ°æ ·æœ¬ä¸­ã€‚

è¯¥ç®—å­ä½¿ç”¨æŒ‡å®šçš„ Hugging Face æ¨¡å‹ä¸ºè¾“å…¥æ ·æœ¬ä¸­çš„å›¾åƒç”Ÿæˆæè¿°ã€‚å®ƒå¯ä»¥ä¸ºæ¯å¼ å›¾åƒç”Ÿæˆå¤šä¸ªæè¿°ï¼Œå¹¶åº”ç”¨ä¸åŒçš„ç­–ç•¥æ¥ä¿ç•™ç”Ÿæˆçš„æè¿°ã€‚è¯¥ç®—å­æ”¯æŒä¸‰ç§ä¿ç•™æ¨¡å¼ï¼š'random_any'ã€'similar_one_simhash' å’Œ 'all'ã€‚åœ¨ 'random_any' æ¨¡å¼ä¸‹ï¼Œéšæœºä¿ç•™ä¸€ä¸ªæè¿°ã€‚åœ¨ 'similar_one_simhash' æ¨¡å¼ä¸‹ï¼Œä¿ç•™ä¸åŸå§‹æ–‡æœ¬æœ€ç›¸ä¼¼çš„æè¿°ï¼ˆåŸºäº SimHashï¼‰ã€‚åœ¨ 'all' æ¨¡å¼ä¸‹ï¼Œæ‰€æœ‰ç”Ÿæˆçš„æè¿°è¢«è¿æ¥å¹¶ä¿ç•™ã€‚è¯¥ç®—å­è¿˜å¯ä»¥æ ¹æ® `keep_original_sample` å‚æ•°ä¿ç•™æˆ–ä¸¢å¼ƒåŸå§‹æ ·æœ¬ã€‚å¦‚æœåŒæ—¶è®¾ç½®äº† `prompt` å’Œ `prompt_key`ï¼Œåˆ™ `prompt_key` ä¼˜å…ˆã€‚

Type ç®—å­ç±»å‹: **mapper**

Tags æ ‡ç­¾: cpu, hf, multimodal

## ğŸ”§ Parameter Configuration å‚æ•°é…ç½®
| name å‚æ•°å | type ç±»å‹ | default é»˜è®¤å€¼ | desc è¯´æ˜ |
|--------|------|--------|------|
| `hf_img2seq` | <class 'str'> | `'Salesforce/blip2-opt-2.7b'` | model name on huggingface to generate caption |
| `trust_remote_code` | <class 'bool'> | `False` | whether to trust the remote code of HF models. |
| `caption_num` | typing.Annotated[int, Gt(gt=0)] | `1` | how many candidate captions to generate for each image |
| `keep_candidate_mode` | <class 'str'> | `'random_any'` | retain strategy for the generated $caption_num$ candidates.      'random_any': Retain the random one from generated captions      'similar_one_simhash': Retain the generated one that is most         similar to the original caption      'all': Retain all generated captions by concatenation  Note:     This is a batched_OP, whose input and output type are     both list. Suppose there are $N$ list of input samples, whose batch     size is $b$, and denote caption_num as $M$.     The number of total samples after generation is $2Nb$ when     keep_original_sample is True and $Nb$ when keep_original_sample is     False. For 'random_any' and 'similar_one_simhash' mode,     it's $(1+M)Nb$ for 'all' mode when keep_original_sample is True     and $MNb$ when keep_original_sample is False. |
| `keep_original_sample` | <class 'bool'> | `True` | whether to keep the original sample. If it's set to False, there will be only generated captions in the final datasets and the original captions will be removed. It's True in default. |
| `prompt` | typing.Optional[str] | `None` | a string prompt to guide the generation of blip2 model for all samples globally. It's None in default, which means no prompt provided. |
| `prompt_key` | typing.Optional[str] | `None` | the key name of fields in samples to store prompts for each sample. It's used for set different prompts for different samples. If it's none, use prompt in parameter "prompt". It's None in default. |
| `args` |  | `''` | extra args |
| `kwargs` |  | `''` | extra args |

## ğŸ“Š Effect demonstration æ•ˆæœæ¼”ç¤º
not available æš‚æ— 

## ğŸ”— related links ç›¸å…³é“¾æ¥
- [source code æºä»£ç ](../../../data_juicer/ops/mapper/image_captioning_mapper.py)
- [unit test å•å…ƒæµ‹è¯•](../../../tests/ops/mapper/test_image_captioning_mapper.py)
- [Return operator list è¿”å›ç®—å­åˆ—è¡¨](../../Operators.md)