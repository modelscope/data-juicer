# image_pair_similarity_filter

Filter to keep image pairs with similarities between images within a specific range.

This operator uses a Hugging Face CLIP model to compute the cosine similarity between two images in each sample. It retains samples where the similarity score falls within the specified minimum and maximum thresholds. The 'any' strategy keeps a sample if any of the image pairs meet the condition, while the 'all' strategy requires all image pairs to meet the condition. The similarity scores are cached in the 'image_pair_similarity' field. Each sample must include exactly two distinct images.

ç”¨äºä¿ç•™å›¾åƒä¹‹é—´ç›¸ä¼¼åº¦åœ¨ç‰¹å®šèŒƒå›´å†…çš„å›¾åƒå¯¹çš„è¿‡æ»¤å™¨ã€‚

è¯¥ç®—å­ä½¿ç”¨Hugging Face CLIPæ¨¡å‹æ¥è®¡ç®—æ¯ä¸ªæ ·æœ¬ä¸­ä¸¤å¼ å›¾åƒä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚å¦‚æœç›¸ä¼¼åº¦å¾—åˆ†è½åœ¨æŒ‡å®šçš„æœ€å°å’Œæœ€å¤§é˜ˆå€¼èŒƒå›´å†…ï¼Œåˆ™ä¿ç•™æ ·æœ¬ã€‚'any'ç­–ç•¥è¦æ±‚è‡³å°‘æœ‰ä¸€å¯¹å›¾åƒæ»¡è¶³æ¡ä»¶å³å¯ä¿ç•™æ ·æœ¬ï¼Œè€Œ'all'ç­–ç•¥è¦æ±‚æ‰€æœ‰å›¾åƒå¯¹éƒ½å¿…é¡»æ»¡è¶³æ¡ä»¶æ‰èƒ½ä¿ç•™æ ·æœ¬ã€‚ç›¸ä¼¼åº¦å¾—åˆ†ç¼“å­˜åœ¨'image_pair_similarity'å­—æ®µä¸­ã€‚æ¯ä¸ªæ ·æœ¬å¿…é¡»åŒ…å«ä¸¤å¼ ä¸åŒçš„å›¾åƒã€‚

Type ç®—å­ç±»å‹: **filter**

Tags æ ‡ç­¾: cpu, hf, image

## ğŸ”§ Parameter Configuration å‚æ•°é…ç½®
| name å‚æ•°å | type ç±»å‹ | default é»˜è®¤å€¼ | desc è¯´æ˜ |
|--------|------|--------|------|
| `hf_clip` |  | `'openai/clip-vit-base-patch32'` | clip model name on huggingface to compute the similarity between image and text. |
| `trust_remote_code` |  | `False` | whether to trust the remote code of HF models. |
| `min_score` | <class 'jsonargparse.typing.ClosedUnitInterval'> | `0.1` | The min similarity to keep samples. |
| `max_score` | <class 'jsonargparse.typing.ClosedUnitInterval'> | `1.0` | The max similarity to keep samples. |
| `any_or_all` | <class 'str'> | `'any'` | keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition. |
| `args` |  | `''` | extra args |
| `kwargs` |  | `''` | extra args |

## ğŸ“Š Effect demonstration æ•ˆæœæ¼”ç¤º
### test_no_eoc_special_token
```python
ImagePairSimilarityFilter(hf_clip='openai/clip-vit-base-patch32', any_or_all='any', min_score=0.85, max_score=1)
```

#### ğŸ“¥ input data è¾“å…¥æ•°æ®
<div class="sample-card" style="border:1px solid #ddd; padding:12px; margin:8px 0; border-radius:6px; background:#fafafa; box-shadow:0 1px 3px rgba(0,0,0,0.1);"><div class="sample-header" style="background:#f8f9fa; padding:4px 8px; margin-bottom:6px; border-radius:3px; font-size:0.9em; color:#666; border-left:3px solid #007acc;"><strong>Sample 1:</strong> text | 2 images</div><pre style="padding:6px; background:#f6f8fa; border-radius:4px; overflow-x:auto; white-space:pre; word-wrap:normal;">image pair 1</pre><div class="media-section" style="margin-bottom:8px;"><div class="media-label" style="font-size:0.85em; color:#666; margin-bottom:4px; font-weight:500;">cat.jpg|img3.jpg:</div><div class="image-grid"><img src="../../../tests/ops/data/cat.jpg" width="160" style="margin:4px;"/><img src="../../../tests/ops/data/img3.jpg" width="160" style="margin:4px;"/></div></div></div><div class="sample-card" style="border:1px solid #ddd; padding:12px; margin:8px 0; border-radius:6px; background:#fafafa; box-shadow:0 1px 3px rgba(0,0,0,0.1);"><div class="sample-header" style="background:#f8f9fa; padding:4px 8px; margin-bottom:6px; border-radius:3px; font-size:0.9em; color:#666; border-left:3px solid #007acc;"><strong>Sample 2:</strong> text | 2 images</div><pre style="padding:6px; background:#f6f8fa; border-radius:4px; overflow-x:auto; white-space:pre; word-wrap:normal;">image pair 2</pre><div class="media-section" style="margin-bottom:8px;"><div class="media-label" style="font-size:0.85em; color:#666; margin-bottom:4px; font-weight:500;">img3.jpg|img7.jpg:</div><div class="image-grid"><img src="../../../tests/ops/data/img3.jpg" width="160" style="margin:4px;"/><img src="../../../tests/ops/data/img7.jpg" width="160" style="margin:4px;"/></div></div></div><div class="sample-card" style="border:1px solid #ddd; padding:12px; margin:8px 0; border-radius:6px; background:#fafafa; box-shadow:0 1px 3px rgba(0,0,0,0.1);"><div class="sample-header" style="background:#f8f9fa; padding:4px 8px; margin-bottom:6px; border-radius:3px; font-size:0.9em; color:#666; border-left:3px solid #007acc;"><strong>Sample 3:</strong> text | 2 images</div><pre style="padding:6px; background:#f6f8fa; border-radius:4px; overflow-x:auto; white-space:pre; word-wrap:normal;">image pair 3</pre><div class="media-section" style="margin-bottom:8px;"><div class="media-label" style="font-size:0.85em; color:#666; margin-bottom:4px; font-weight:500;">img2.jpg|img5.jpg:</div><div class="image-grid"><img src="../../../tests/ops/data/img2.jpg" width="160" style="margin:4px;"/><img src="../../../tests/ops/data/img5.jpg" width="160" style="margin:4px;"/></div></div></div>

#### ğŸ“¤ output data è¾“å‡ºæ•°æ®
<div class="sample-card" style="border:1px solid #ddd; padding:12px; margin:8px 0; border-radius:6px; background:#fafafa; box-shadow:0 1px 3px rgba(0,0,0,0.1);"><div class="sample-header" style="background:#f8f9fa; padding:4px 8px; margin-bottom:6px; border-radius:3px; font-size:0.9em; color:#666; border-left:3px solid #007acc;"><strong>Sample 1:</strong> text | 2 images</div><pre style="padding:6px; background:#f6f8fa; border-radius:4px; overflow-x:auto; white-space:pre; word-wrap:normal;">image pair 2</pre><div class="media-section" style="margin-bottom:8px;"><div class="media-label" style="font-size:0.85em; color:#666; margin-bottom:4px; font-weight:500;">img3.jpg|img7.jpg:</div><div class="image-grid"><img src="../../../tests/ops/data/img3.jpg" width="160" style="margin:4px;"/><img src="../../../tests/ops/data/img7.jpg" width="160" style="margin:4px;"/></div></div><div class='meta' style='margin:6px 0;'><table class='meta-table' style='border-collapse:collapse; width:100%; border:1px solid #e3e3e3;'><tr><th colspan='2' style='text-align:left; vertical-align:top; padding:6px 8px; font-weight:600; border-bottom:1px solid #e3e3e3;'>__dj__stats__</th></tr><tr><td style='text-align:left; vertical-align:top; padding:4px 8px; padding-left:22px; font-weight:500; color:#444; border-bottom:1px solid #e3e3e3; white-space:nowrap;'>image_pair_similarity</td><td style='text-align:left; vertical-align:top; padding:4px 6px; padding-left:4px; border-bottom:1px solid #e3e3e3;'>[0.9999999403953552]</td></tr></table></div></div>

#### âœ¨ explanation è§£é‡Š
This example demonstrates the operator's ability to filter out image pairs based on their similarity scores. The operator uses a Hugging Face CLIP model to calculate the cosine similarity between two images in each sample. In this case, the operator is set to keep samples where any of the image pairs have a similarity score between 0.85 and 1. The output data shows that only 'image pair 2' is retained because its images (img3.jpg and img7.jpg) have a similarity score of approximately 1, which falls within the specified range. The 'meta' field in the output contains the calculated similarity score for the retained sample.
è¿™ä¸ªä¾‹å­å±•ç¤ºäº†ç®—å­åŸºäºå›¾åƒå¯¹ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°è¿›è¡Œè¿‡æ»¤çš„èƒ½åŠ›ã€‚ç®—å­ä½¿ç”¨Hugging Faceçš„CLIPæ¨¡å‹æ¥è®¡ç®—æ¯ä¸ªæ ·æœ¬ä¸­ä¸¤ä¸ªå›¾åƒä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç®—å­è®¾ç½®ä¸ºä¿ç•™ä»»ä½•å›¾åƒå¯¹çš„ç›¸ä¼¼åº¦åˆ†æ•°åœ¨0.85åˆ°1ä¹‹é—´çš„æ ·æœ¬ã€‚è¾“å‡ºæ•°æ®æ˜¾ç¤ºåªæœ‰'image pair 2'è¢«ä¿ç•™äº†ï¼Œå› ä¸ºå®ƒçš„å›¾åƒï¼ˆimg3.jpg å’Œ img7.jpgï¼‰çš„ç›¸ä¼¼åº¦åˆ†æ•°çº¦ä¸º1ï¼Œè½åœ¨æŒ‡å®šèŒƒå›´å†…ã€‚è¾“å‡ºä¸­çš„'meta'å­—æ®µåŒ…å«äº†ä¿ç•™æ ·æœ¬çš„è®¡ç®—å‡ºçš„ç›¸ä¼¼åº¦åˆ†æ•°ã€‚


## ğŸ”— related links ç›¸å…³é“¾æ¥
- [source code æºä»£ç ](../../../data_juicer/ops/filter/image_pair_similarity_filter.py)
- [unit test å•å…ƒæµ‹è¯•](../../../tests/ops/filter/test_image_pair_similarity_filter.py)
- [Return operator list è¿”å›ç®—å­åˆ—è¡¨](../../Operators.md)