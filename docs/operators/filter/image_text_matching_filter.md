# image_text_matching_filter

Filter to keep samples with image-text matching scores within a specific range.

This operator uses a Hugging Face BLIP model to compute the matching score between images and text. It keeps samples where the matching score falls within the specified `min_score` and `max_score` range. The key metric, `image_text_matching_score`, is computed for each image-text pair. If multiple images are associated with a single text, the scores can be reduced using 'avg', 'max', or 'min' modes. The operator supports horizontal and vertical flipping of images. Samples are kept based on either 'any' or 'all' strategy: 'any' keeps the sample if any image meets the condition, while 'all' keeps the sample only if all images meet the condition.

ç”¨æ¥ä¿ç•™å›¾åƒ-æ–‡æœ¬åŒ¹é…åˆ†æ•°åœ¨ç‰¹å®šèŒƒå›´å†…çš„æ ·æœ¬çš„è¿‡æ»¤å™¨ã€‚

è¯¥ç®—å­ä½¿ç”¨ Hugging Face BLIP æ¨¡å‹è®¡ç®—å›¾åƒå’Œæ–‡æœ¬ä¹‹é—´çš„åŒ¹é…åˆ†æ•°ã€‚å®ƒä¿ç•™åŒ¹é…åˆ†æ•°è½åœ¨æŒ‡å®š `min_score` å’Œ `max_score` èŒƒå›´å†…çš„æ ·æœ¬ã€‚å…³é”®æŒ‡æ ‡ `image_text_matching_score` ä¸ºæ¯ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹è®¡ç®—ã€‚å¦‚æœå¤šä¸ªå›¾åƒä¸å•ä¸ªæ–‡æœ¬ç›¸å…³è”ï¼Œå¯ä»¥ä½¿ç”¨ 'avg'ã€'max' æˆ– 'min' æ¨¡å¼æ¥å½’çº¦åˆ†æ•°ã€‚è¯¥ç®—å­æ”¯æŒå›¾åƒçš„æ°´å¹³å’Œå‚ç›´ç¿»è½¬ã€‚æ ¹æ® 'any' æˆ– 'all' ç­–ç•¥ä¿ç•™æ ·æœ¬ï¼š'any' è¡¨ç¤ºåªè¦æœ‰ä»»ä½•ä¸€ä¸ªå›¾åƒæ»¡è¶³æ¡ä»¶å°±ä¿ç•™æ ·æœ¬ï¼Œè€Œ 'all' åˆ™è¡¨ç¤ºåªæœ‰å½“æ‰€æœ‰å›¾åƒéƒ½æ»¡è¶³æ¡ä»¶æ—¶æ‰ä¿ç•™æ ·æœ¬ã€‚

Type ç®—å­ç±»å‹: **filter**

Tags æ ‡ç­¾: cpu, hf, multimodal

## ğŸ”§ Parameter Configuration å‚æ•°é…ç½®
| name å‚æ•°å | type ç±»å‹ | default é»˜è®¤å€¼ | desc è¯´æ˜ |
|--------|------|--------|------|
| `hf_blip` | <class 'str'> | `'Salesforce/blip-itm-base-coco'` | blip model name on huggingface to compute the matching score between image and text. |
| `trust_remote_code` | <class 'bool'> | `False` | whether to trust the remote code of HF models. |
| `min_score` | <class 'float'> | `0.003` | The min matching score to keep samples. |
| `max_score` | <class 'float'> | `1.0` | The max matching score to keep samples. |
| `horizontal_flip` | <class 'bool'> | `False` | Flip image horizontally (left to right). |
| `vertical_flip` | <class 'bool'> | `False` | Flip image vertically (top to bottom). |
| `any_or_all` | <class 'str'> | `'any'` | keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition. |
| `reduce_mode` | <class 'str'> | `'avg'` | reduce mode when one text corresponds to multiple images in a chunk. 'avg': Take the average of multiple values 'max': Take the max of multiple values 'min': Take the min of multiple values |
| `args` |  | `''` | extra args |
| `kwargs` |  | `''` | extra args |

## ğŸ“Š Effect demonstration æ•ˆæœæ¼”ç¤º
### test_keep_any
```python
ImageTextMatchingFilter(hf_blip='Salesforce/blip-itm-base-coco', reduce_mode='avg', any_or_all='any', min_score=0.003, max_score=1.0)
```

#### ğŸ“¥ input data è¾“å…¥æ•°æ®
<div class="sample-card" style="border:1px solid #ddd; padding:12px; margin:8px 0; border-radius:6px; background:#fafafa; box-shadow:0 1px 3px rgba(0,0,0,0.1);"><div class="sample-header" style="background:#f8f9fa; padding:4px 8px; margin-bottom:6px; border-radius:3px; font-size:0.9em; color:#666; border-left:3px solid #007acc;"><strong>Sample 1:</strong> text | 2 images</div><pre style="padding:6px; background:#f6f8fa; border-radius:4px; overflow-x:auto; white-space:pre; word-wrap:normal;">&lt;__dj__image&gt;a woman sitting on the beach with a dog &lt;|__dj__eoc|&gt; &lt;__dj__image&gt;a man sitting on the grass with a cat &lt;|__dj__eoc|&gt;</pre><div class="media-section" style="margin-bottom:8px;"><div class="media-label" style="font-size:0.85em; color:#666; margin-bottom:4px; font-weight:500;">blip.jpg|blip.jpg:</div><div class="image-grid"><img src="../../../tests/ops/data/blip.jpg" width="160" style="margin:4px;"/><img src="../../../tests/ops/data/blip.jpg" width="160" style="margin:4px;"/></div></div></div>

#### ğŸ“¤ output data è¾“å‡ºæ•°æ®
<div class="sample-card" style="border:1px solid #ddd; padding:12px; margin:8px 0; border-radius:6px; background:#fafafa; box-shadow:0 1px 3px rgba(0,0,0,0.1);"><div class="sample-header" style="background:#f8f9fa; padding:4px 8px; margin-bottom:6px; border-radius:3px; font-size:0.9em; color:#666; border-left:3px solid #007acc;"><strong>Sample 1:</strong> text | 2 images</div><pre style="padding:6px; background:#f6f8fa; border-radius:4px; overflow-x:auto; white-space:pre; word-wrap:normal;">&lt;__dj__image&gt;a woman sitting on the beach with a dog &lt;|__dj__eoc|&gt; &lt;__dj__image&gt;a man sitting on the grass with a cat &lt;|__dj__eoc|&gt;</pre><div class="media-section" style="margin-bottom:8px;"><div class="media-label" style="font-size:0.85em; color:#666; margin-bottom:4px; font-weight:500;">blip.jpg|blip.jpg:</div><div class="image-grid"><img src="../../../tests/ops/data/blip.jpg" width="160" style="margin:4px;"/><img src="../../../tests/ops/data/blip.jpg" width="160" style="margin:4px;"/></div></div></div>

#### âœ¨ explanation è§£é‡Š
The operator keeps samples if any of the image-text pairs have a matching score within the specified range. In this case, at least one of the image-text pairs meets the criteria, so the sample is kept.
ç®—å­åœ¨ä»»ä½•å›¾åƒ-æ–‡æœ¬å¯¹çš„åŒ¹é…åˆ†æ•°è½åœ¨æŒ‡å®šèŒƒå›´å†…æ—¶ä¿ç•™æ ·æœ¬ã€‚æ­¤ä¾‹ä¸­ï¼Œè‡³å°‘æœ‰ä¸€ç»„å›¾åƒ-æ–‡æœ¬å¯¹æ»¡è¶³æ¡ä»¶ï¼Œå› æ­¤è¯¥æ ·æœ¬è¢«ä¿ç•™ã€‚

### test_keep_all
```python
ImageTextMatchingFilter(hf_blip='Salesforce/blip-itm-base-coco', reduce_mode='avg', any_or_all='all', min_score=0.003, max_score=1.0)
```

#### ğŸ“¥ input data è¾“å…¥æ•°æ®
<div class="sample-card" style="border:1px solid #ddd; padding:12px; margin:8px 0; border-radius:6px; background:#fafafa; box-shadow:0 1px 3px rgba(0,0,0,0.1);"><div class="sample-header" style="background:#f8f9fa; padding:4px 8px; margin-bottom:6px; border-radius:3px; font-size:0.9em; color:#666; border-left:3px solid #007acc;"><strong>Sample 1:</strong> text | 2 images</div><pre style="padding:6px; background:#f6f8fa; border-radius:4px; overflow-x:auto; white-space:pre; word-wrap:normal;">&lt;__dj__image&gt;a woman sitting on the beach with a dog &lt;|__dj__eoc|&gt; &lt;__dj__image&gt;a man sitting on the grass with a cat &lt;|__dj__eoc|&gt;</pre><div class="media-section" style="margin-bottom:8px;"><div class="media-label" style="font-size:0.85em; color:#666; margin-bottom:4px; font-weight:500;">blip.jpg|blip.jpg:</div><div class="image-grid"><img src="../../../tests/ops/data/blip.jpg" width="160" style="margin:4px;"/><img src="../../../tests/ops/data/blip.jpg" width="160" style="margin:4px;"/></div></div></div>

#### ğŸ“¤ output data è¾“å‡ºæ•°æ®
<div class="sample-card" style="border:1px solid #ddd; padding:12px; margin:8px 0; border-radius:6px; background:#fafafa; box-shadow:0 1px 3px rgba(0,0,0,0.1);"><div class="sample-header" style="background:#f8f9fa; padding:4px 8px; margin-bottom:6px; border-radius:3px; font-size:0.9em; color:#666; border-left:3px solid #007acc;"><strong>Sample 1:</strong> text</div><pre style="padding:6px; background:#f6f8fa; border-radius:4px; overflow-x:auto; white-space:pre; word-wrap:normal;">[]</pre></div>

#### âœ¨ explanation è§£é‡Š
The operator only keeps samples if all of the image-text pairs have a matching score within the specified range. In this case, not all image-text pairs meet the criteria, so the sample is removed.
ç®—å­ä»…åœ¨æ‰€æœ‰å›¾åƒ-æ–‡æœ¬å¯¹çš„åŒ¹é…åˆ†æ•°éƒ½è½åœ¨æŒ‡å®šèŒƒå›´å†…æ—¶æ‰ä¿ç•™æ ·æœ¬ã€‚æ­¤ä¾‹ä¸­ï¼Œå¹¶éæ‰€æœ‰çš„å›¾åƒ-æ–‡æœ¬å¯¹éƒ½æ»¡è¶³æ¡ä»¶ï¼Œå› æ­¤è¯¥æ ·æœ¬è¢«ç§»é™¤ã€‚


## ğŸ”— related links ç›¸å…³é“¾æ¥
- [source code æºä»£ç ](../../../data_juicer/ops/filter/image_text_matching_filter.py)
- [unit test å•å…ƒæµ‹è¯•](../../../tests/ops/filter/test_image_text_matching_filter.py)
- [Return operator list è¿”å›ç®—å­åˆ—è¡¨](../../Operators.md)