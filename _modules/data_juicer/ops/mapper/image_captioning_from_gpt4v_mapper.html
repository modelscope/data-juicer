

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>data_juicer.ops.mapper.image_captioning_from_gpt4v_mapper &mdash; data_juicer 1.3.3 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../../_static/documentation_options.js?v=28d163b9"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            data_juicer
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.core.html">data_juicer.core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.ops.html">data_juicer.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.ops.filter.html">data_juicer.ops.filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.ops.mapper.html">data_juicer.ops.mapper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.ops.deduplicator.html">data_juicer.ops.deduplicator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.ops.selector.html">data_juicer.ops.selector</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.ops.common.html">data_juicer.ops.common</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.analysis.html">data_juicer.analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.config.html">data_juicer.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data_juicer.format.html">data_juicer.format</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">data_juicer</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
          <li class="breadcrumb-item"><a href="../../../data_juicer.html">data_juicer</a></li>
      <li class="breadcrumb-item active">data_juicer.ops.mapper.image_captioning_from_gpt4v_mapper</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for data_juicer.ops.mapper.image_captioning_from_gpt4v_mapper</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">Field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">data_juicer.utils.mm_utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">SpecialTokens</span><span class="p">,</span> <span class="n">image_byte_to_base64</span><span class="p">,</span>
                                        <span class="n">insert_texts_after_placeholders</span><span class="p">,</span>
                                        <span class="n">load_image_byte</span><span class="p">,</span>
                                        <span class="n">remove_non_special_tokens</span><span class="p">,</span>
                                        <span class="n">remove_special_tokens</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">..base_op</span><span class="w"> </span><span class="kn">import</span> <span class="n">OPERATORS</span><span class="p">,</span> <span class="n">Mapper</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..op_fusion</span><span class="w"> </span><span class="kn">import</span> <span class="n">LOADED_IMAGES</span>

<span class="n">SYSTEM_PROMPTS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;reasoning&#39;</span><span class="p">:</span>
    <span class="s2">&quot;You are an AI visual assistant that can analyze a single image. The task is to use the provided image, create a plausible question about the image, and provide the answer in detail.</span><span class="se">\n\n</span><span class="s2">You can create complex questions beyond describing the scene. Make the question challenging by not including the visual content details in the question so that the user needs to reason about that first.</span><span class="se">\n\n</span><span class="s2">To answer such questions, you should require first understanding the visual content, then based on the background knowledge or reasoning, either explain why the things are happening that way, or provide guides and help to user&#39;s request. </span><span class="se">\n\n</span><span class="s2">Please give the Q&amp;A content directly and separate questions and answers with Q and A.&quot;</span><span class="p">,</span>  <span class="c1"># noqa: E501</span>
    <span class="s1">&#39;description&#39;</span><span class="p">:</span>
    <span class="s1">&#39;You are an AI visual assistant that can analyze a single image. The task is to use the provided image, create a reasonable question that describes the content of the image, and provide the answer in detail.</span><span class="se">\n\n</span><span class="s1">Please give the Q&amp;A content directly and separate questions and answers with Q and A.&#39;</span><span class="p">,</span>  <span class="c1"># noqa: E501</span>
    <span class="s1">&#39;conversation&#39;</span><span class="p">:</span>
    <span class="s1">&#39;You are an AI visual assistant, and you are seeing a single image.</span><span class="se">\n\n</span><span class="s1">Design a conversation between you and a person asking about this image. The answers should be in a tone that a visual AI assistant is seeing the image and answering the question. Ask diverse questions and give corresponding answers.</span><span class="se">\n\n</span><span class="s1">Include questions asking about the visual content of the image, including the object types, counting the objects, object actions, object locations, relative positions between objects, etc. Only include questions that have definite answers:</span><span class="se">\n</span><span class="s1">(1) one can see the content in the image that the question asks about and can answer confidently;</span><span class="se">\n</span><span class="s1">(2) one can determine confidently from the image that it is not in the image.</span><span class="se">\n</span><span class="s1">Do not ask any question that cannot be answered confidently.</span><span class="se">\n\n</span><span class="s1">Conversation also include complex questions that are relevant to the content in the image, for example, asking about background knowledge of the objects in the image, asking to discuss about events happening in the image, etc. Again, do not ask about uncertain details.</span><span class="se">\n</span><span class="s1">Provide detailed answers when answering complex questions. For example, give detailed examples or reasoning steps to make the content more convincing and well-organized. Please give the content of the conversation directly and separate questions and answers with Q and A&#39;</span>  <span class="c1"># noqa: E501</span>
<span class="p">}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">call_gpt_vision_api</span><span class="p">(</span><span class="n">api_key</span><span class="p">,</span>
                        <span class="n">system_prompt</span><span class="p">,</span>
                        <span class="n">user_prompt</span><span class="p">,</span>
                        <span class="n">base64_image</span><span class="p">,</span>
                        <span class="n">max_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                        <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                        <span class="n">model</span><span class="o">=</span><span class="s1">&#39;gpt-4-vision-preview&#39;</span><span class="p">):</span>
    <span class="n">api_url</span> <span class="o">=</span> <span class="s1">&#39;https://api.openai.com/v1/chat/completions&#39;</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Authorization&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Bearer </span><span class="si">{</span><span class="n">api_key</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="p">}</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;model&#39;</span><span class="p">:</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="s1">&#39;messages&#39;</span><span class="p">:</span> <span class="p">[{</span>
            <span class="s1">&#39;role&#39;</span><span class="p">:</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span>
            <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">system_prompt</span>
        <span class="p">},</span> <span class="p">{</span>
            <span class="s1">&#39;role&#39;</span><span class="p">:</span>
            <span class="s1">&#39;user&#39;</span><span class="p">,</span>
            <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="p">[{</span>
                <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;text&#39;</span><span class="p">,</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">user_prompt</span>
            <span class="p">},</span> <span class="p">{</span>
                <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;image_url&#39;</span><span class="p">,</span>
                <span class="s1">&#39;image_url&#39;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s1">&#39;url&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;data:image/jpeg;base64,</span><span class="si">{</span><span class="n">base64_image</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;detail&#39;</span><span class="p">:</span> <span class="s1">&#39;low&#39;</span>
                <span class="p">}</span>
            <span class="p">}]</span>
        <span class="p">}],</span>
        <span class="s1">&#39;max_tokens&#39;</span><span class="p">:</span>
        <span class="n">max_tokens</span><span class="p">,</span>
        <span class="s1">&#39;temperature&#39;</span><span class="p">:</span>
        <span class="n">temperature</span>
    <span class="p">}</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">api_url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

        <span class="k">if</span> <span class="s1">&#39;choices&#39;</span> <span class="ow">in</span> <span class="n">result</span> <span class="ow">and</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;choices&#39;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;choices&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;text&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;No results returned from the API, return None.&#39;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">HTTPError</span> <span class="k">as</span> <span class="n">errh</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">errh</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">401</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Invalid API key provided.&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">errh</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">429</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s1">&#39;API request limit has been reached. Please try again later.&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;HTTP error occurred: </span><span class="si">{</span><span class="n">errh</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">ConnectionError</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Network error occurred. Please check your connection.&#39;</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">Timeout</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;The request timed out. Please try again later.&#39;</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warningt</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;An error occurred: </span><span class="si">{</span><span class="n">err</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;An unexpected error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;API request failed, return None.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">None</span>


<div class="viewcode-block" id="ImageCaptioningFromGPT4VMapper">
<a class="viewcode-back" href="../../../../data_juicer.ops.mapper.html#data_juicer.ops.mapper.ImageCaptioningFromGPT4VMapper">[docs]</a>
<span class="nd">@OPERATORS</span><span class="o">.</span><span class="n">register_module</span><span class="p">(</span><span class="s1">&#39;image_captioning_from_gpt4v_mapper&#39;</span><span class="p">)</span>
<span class="nd">@LOADED_IMAGES</span><span class="o">.</span><span class="n">register_module</span><span class="p">(</span><span class="s1">&#39;image_captioning_from_gpt4v_mapper&#39;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ImageCaptioningFromGPT4VMapper</span><span class="p">(</span><span class="n">Mapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mapper to generate samples whose texts are generated based on</span>
<span class="sd">    gpt-4-vision and the image.&quot;&quot;&quot;</span>

    <span class="n">_batched_op</span> <span class="o">=</span> <span class="kc">True</span>

<div class="viewcode-block" id="ImageCaptioningFromGPT4VMapper.__init__">
<a class="viewcode-back" href="../../../../data_juicer.ops.mapper.html#data_juicer.ops.mapper.ImageCaptioningFromGPT4VMapper.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;description&#39;</span><span class="p">,</span>
                 <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                 <span class="n">max_token</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
                 <span class="n">temperature</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Field</span><span class="p">(</span><span class="n">ge</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">le</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                 <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                 <span class="n">user_prompt_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">keep_original_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">any_or_all</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;any&#39;</span><span class="p">,</span>
                 <span class="o">*</span><span class="n">args</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialization method.</span>

<span class="sd">        :param mode: mode of text generated from images, can be one of</span>
<span class="sd">            [&#39;reasoning&#39;, &#39;description&#39;, &#39;conversation&#39;, &#39;custom&#39;]</span>
<span class="sd">        :param api_key: the API key to authenticate the request.</span>
<span class="sd">        :param max_token: the maximum number of tokens to generate.</span>
<span class="sd">            Default is 500.</span>
<span class="sd">        :param temperature: controls the randomness of the output (range</span>
<span class="sd">            from 0 to 1). Default is 0.</span>
<span class="sd">        :param system_prompt: a string prompt used to set the context of a</span>
<span class="sd">            conversation and provide global guidance or rules for the</span>
<span class="sd">            gpt4-vision so that it can  generate responses in the expected way.</span>
<span class="sd">            If `mode` set to `custom`, the parameter will be used.</span>
<span class="sd">        :param user_prompt: a string prompt to guide the generation of</span>
<span class="sd">            gpt4-vision for each samples. It&#39;s &quot;&quot; in default, which means no</span>
<span class="sd">            prompt provided.</span>
<span class="sd">        :param user_prompt_key: the key name of fields in samples to store</span>
<span class="sd">            prompts for each sample. It&#39;s used for set different prompts for</span>
<span class="sd">            different samples. If it&#39;s none, use prompt in parameter &quot;prompt&quot;.</span>
<span class="sd">            It&#39;s None in default.</span>
<span class="sd">        :param keep_original_sample: whether to keep the original sample. If</span>
<span class="sd">            it&#39;s set to False, there will be only generated text in the</span>
<span class="sd">            final datasets and the original text will be removed. It&#39;s True</span>
<span class="sd">            in default.</span>
<span class="sd">        :param any_or_all: keep this sample with &#39;any&#39; or &#39;all&#39; strategy of</span>
<span class="sd">            all images. &#39;any&#39;: keep this sample if any images meet the</span>
<span class="sd">            condition. &#39;all&#39;: keep this sample only if all images meet the</span>
<span class="sd">            condition.</span>
<span class="sd">        :param args: extra args</span>
<span class="sd">        :param kwargs: extra args</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;reasoning&#39;</span><span class="p">,</span> <span class="s1">&#39;description&#39;</span><span class="p">,</span> <span class="s1">&#39;conversation&#39;</span><span class="p">,</span> <span class="s1">&#39;custom&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;Mode [</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s1">] is not supported. &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;Can only be one of &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;[&quot;reasoning&quot;, &quot;description&quot;, &quot;conversation&quot;, &quot;custom&quot;].&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">system_prompt</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;The parameter `mode` set to `[custom]`. Data-Juicer &#39;</span>
                        <span class="s1">&#39;will use `system_prompt` to generate text.&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">SYSTEM_PROMPTS</span><span class="p">[</span><span class="n">mode</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;The parameter `mode` set to [</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s1">]. Data-Juicer will &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;use default prompt to generate text.&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">api_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_token</span> <span class="o">=</span> <span class="n">max_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_prompt</span> <span class="o">=</span> <span class="n">user_prompt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_prompt_key</span> <span class="o">=</span> <span class="n">user_prompt_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep_original_sample</span> <span class="o">=</span> <span class="n">keep_original_sample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">any_or_all</span> <span class="o">=</span> <span class="n">any_or_all</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extra_args</span> <span class="o">=</span> <span class="n">kwargs</span>

        <span class="c1"># report a warning when both user_prompt and user_prompt_key are set</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_prompt</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_prompt_key</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s1">&#39;Both the parameter `user_prompt` and `user_prompt_key` are &#39;</span>
                <span class="s1">&#39;set. Data-Juicer will consider `user_prompt_key` first.&#39;</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_process_single_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
        <span class="c1"># there is no image in this sample</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sample</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">image_key</span><span class="p">]:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># the generated results</span>
        <span class="n">generated_sample</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
        <span class="n">generated_sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="c1"># load all image(s)</span>
        <span class="n">loaded_image_keys</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">image_key</span><span class="p">]</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">loaded_image_key</span> <span class="ow">in</span> <span class="n">loaded_image_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">loaded_image_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
                <span class="c1"># avoid loading the same images</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">load_image_byte</span><span class="p">(</span><span class="n">loaded_image_key</span><span class="p">)</span>
                <span class="n">images</span><span class="p">[</span><span class="n">loaded_image_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">image</span>

        <span class="c1"># construct user prompts</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_prompt_key</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">user_prompt_key</span><span class="p">],</span>
                                               <span class="nb">str</span><span class="p">):</span>
            <span class="c1"># check user_prompt_key is not None, and it&#39;s a str in the sample</span>
            <span class="n">prompt_texts</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">user_prompt_key</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_prompt</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="c1"># check prompt is not None, and it&#39;s a str</span>
            <span class="n">prompt_texts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_prompt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt_texts</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># do generation for each image chunk by chunk</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">SpecialTokens</span><span class="o">.</span><span class="n">eoc</span><span class="p">):</span>
            <span class="c1"># skip empty chunks or contents after the last eoc token</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">chunk</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                <span class="k">continue</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">img_count</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">SpecialTokens</span><span class="o">.</span><span class="n">image</span><span class="p">)</span>
                <span class="n">text_with_only_special_tokens</span> <span class="o">=</span> <span class="n">remove_non_special_tokens</span><span class="p">(</span>
                    <span class="n">chunk</span><span class="p">)</span>
                <span class="n">generated_text_single_chunk</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">image_key</span> <span class="ow">in</span> <span class="n">loaded_image_keys</span><span class="p">[</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span> <span class="o">+</span> <span class="n">img_count</span><span class="p">]:</span>
                    <span class="n">image</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">image_key</span><span class="p">]</span>
                    <span class="n">res</span> <span class="o">=</span> <span class="n">call_gpt_vision_api</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">api_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">,</span>
                                              <span class="n">prompt_texts</span><span class="p">,</span>
                                              <span class="n">image_byte_to_base64</span><span class="p">(</span><span class="n">image</span><span class="p">),</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">max_token</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>
                    <span class="n">generated_text_single_chunk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">any_or_all</span> <span class="o">==</span> <span class="s1">&#39;all&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
                        <span class="n">generated_text_single_chunk</span><span class="p">):</span>
                    <span class="k">return</span> <span class="p">[]</span>

                <span class="c1"># insert the generated text according to given mode</span>
                <span class="n">place_holders</span> <span class="o">=</span> <span class="p">[</span><span class="n">SpecialTokens</span><span class="o">.</span><span class="n">image</span><span class="p">]</span> <span class="o">*</span> <span class="n">img_count</span>
                <span class="n">new_generated_text_per_chunk</span> <span class="o">=</span> <span class="n">insert_texts_after_placeholders</span><span class="p">(</span>
                    <span class="n">original_string</span><span class="o">=</span><span class="n">text_with_only_special_tokens</span><span class="p">,</span>
                    <span class="n">placeholders</span><span class="o">=</span><span class="n">place_holders</span><span class="p">,</span>
                    <span class="n">new_texts</span><span class="o">=</span><span class="n">generated_text_single_chunk</span><span class="p">)</span>
                <span class="n">generated_sample</span><span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span>
                    <span class="n">text_key</span><span class="p">]</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">new_generated_text_per_chunk</span><span class="si">}{</span><span class="n">SpecialTokens</span><span class="o">.</span><span class="n">eoc</span><span class="si">}</span><span class="s1">&#39;</span>  <span class="c1"># noqa: E501</span>
                <span class="n">offset</span> <span class="o">+=</span> <span class="n">img_count</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">any_or_all</span> <span class="o">==</span> <span class="s1">&#39;any&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">remove_special_tokens</span><span class="p">(</span>
                <span class="n">generated_sample</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">]):</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">generated_sample</span><span class="p">]</span>

<div class="viewcode-block" id="ImageCaptioningFromGPT4VMapper.process_batched">
<a class="viewcode-back" href="../../../../data_juicer.ops.mapper.html#data_juicer.ops.mapper.ImageCaptioningFromGPT4VMapper.process_batched">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">process_batched</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
        <span class="c1"># reconstruct samples from &quot;dict of lists&quot; to &quot;list of dicts&quot;</span>
        <span class="n">reconstructed_samples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_key</span><span class="p">])):</span>
            <span class="n">reconstructed_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">samples</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                 <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">})</span>
        <span class="n">samples_after_generation</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># do generation for each sample within the batch</span>
        <span class="k">for</span> <span class="n">ori_sample</span> <span class="ow">in</span> <span class="n">reconstructed_samples</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_original_sample</span><span class="p">:</span>
                <span class="n">samples_after_generation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ori_sample</span><span class="p">)</span>
            <span class="n">generated_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_single_sample</span><span class="p">(</span><span class="n">ori_sample</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">generated_samples</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">samples_after_generation</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">generated_samples</span><span class="p">)</span>
        <span class="c1"># reconstruct samples from &quot;list of dicts&quot; to &quot;dict of lists&quot;</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">samples_after_generation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="n">res_samples</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="n">res_samples</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples_after_generation</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">res_samples</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Data-Juicer Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>